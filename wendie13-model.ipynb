{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset dari kaggle\n",
        "Sumber dataset : https://www.kaggle.com/datasets/dineshpiyasamara/sentiment-analysis-dataset"
      ],
      "metadata": {
        "id": "uda4ysz58-H_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "58xGaCfLNfdE",
        "outputId": "555de99e-ec11-4ba3-d163-49335e541ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tfx\n",
            "  Downloading tfx-1.15.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ml-pipelines-sdk==1.15.1 (from tfx)\n",
            "  Downloading ml_pipelines_sdk-1.15.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.4.0)\n",
            "Collecting ml-metadata<1.16.0,>=1.15.0 (from tfx)\n",
            "  Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: packaging>=22 in /usr/local/lib/python3.10/dist-packages (from tfx) (24.2)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.5.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.25.5)\n",
            "Collecting docker<5,>=4.1 (from tfx)\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-apitools<1,>=0.5 (from tfx)\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-api-python-client<2,>=1.8 (from tfx)\n",
            "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.1.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.12.2)\n",
            "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting attrs<24,>=19.3.0 (from tfx)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: click<9,>=7 in /usr/local/lib/python3.10/dist-packages (from tfx) (8.1.7)\n",
            "Requirement already satisfied: google-api-core<3 in /usr/local/lib/python3.10/dist-packages (from tfx) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.73.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.25.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.68.1)\n",
            "Collecting keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4 (from tfx)\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting kubernetes<13,>=10.0.1 (from tfx)\n",
            "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.26.4)\n",
            "Collecting pyarrow<11,>=10 (from tfx)\n",
            "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting scipy<1.13 (from tfx)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=6 in /usr/local/lib/python3.10/dist-packages (from tfx) (6.0.2)\n",
            "Collecting tensorflow<2.16,>=2.15.0 (from tfx)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-hub<0.16,>=0.15.0 (from tfx)\n",
            "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tensorflow-data-validation<1.16.0,>=1.15.1 (from tfx)\n",
            "  Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting tensorflow-model-analysis<0.47.0,>=0.46.0 (from tfx)\n",
            "  Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting tensorflow-serving-api<2.16,>=2.15 (from tfx)\n",
            "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-transform<1.16.0,>=1.15.0 (from tfx)\n",
            "  Downloading tensorflow_transform-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tfx-bsl<1.16.0,>=1.15.1 (from tfx)\n",
            "  Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.10.12)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio<2,>=1.28.1 (from tfx)\n",
            "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (1.25.0)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.9.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.32.3)\n",
            "Collecting sortedcontainers>=2.4.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.6)\n",
            "Requirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (5.5.0)\n",
            "Collecting google-apitools<1,>=0.5 (from tfx)\n",
            "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.2.0)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.20.1)\n",
            "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.1)\n",
            "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_pubsublite-1.11.1-py2.py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-cloud-storage<3,>=2.18.2 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.4.1)\n",
            "Requirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\n",
            "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_spanner-3.51.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_dlp-3.25.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.15.1)\n",
            "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_videointelligence-2.14.1-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_vision-3.8.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading google_cloud_recommendations_ai-0.10.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keyrings.google-artifactregistry-auth (from apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker<5,>=4.1->tfx) (1.16.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<5,>=4.1->tfx) (1.8.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3->tfx) (1.66.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client<2,>=1.8->tfx)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (1.13.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.10.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (0.16)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=3->tfx) (2.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4,>=2.7.3->tfx) (3.0.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (3.5.0)\n",
            "Collecting kt-legacy (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2024.8.30)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (75.1.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2.2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker<2,>=1.3.1->tfx) (5.9.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (2.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tfx) (0.37.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tfx)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx) (1.4.2)\n",
            "Collecting pandas<2,>=1.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx)\n",
            "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-metadata<1.16,>=1.15.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx)\n",
            "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipython<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (7.7.1)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (11.0.0)\n",
            "Collecting rouge-score<2,>=0.1.2 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu<4,>=2.3 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tfx) (0.45.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx) (0.13.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.28.2)\n",
            "Collecting overrides<8.0.0,>=6.0.1 (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx) (0.5.2)\n",
            "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.18.2->apache-beam[gcp]<3,>=2.47->tfx) (1.6.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.2.0)\n",
            "Collecting jedi>=0.16 (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.0.13)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.22.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2,>=1.6.2->tfx) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2,>=1.6.2->tfx) (2.27.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.10)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.9.0)\n",
            "Collecting colorama (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx) (3.1.3)\n",
            "Collecting protobuf<5,>=3.20.3 (from tfx)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: keyring in /usr/lib/python3/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx) (23.5.0)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.10/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx) (1.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.2.2)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.8.4)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (0.49b2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.5.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.66.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (3.21.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.1.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.10.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.21.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (0.5.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (3.7.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx) (1.2.2)\n",
            "Downloading tfx-1.15.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_pipelines_sdk-1.15.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_analysis-0.46.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
            "Downloading tensorflow_transform-1.15.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading google_cloud_dlp-3.25.1-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_pubsublite-1.11.1-py2.py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_recommendations_ai-0.10.14-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.7/193.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_spanner-3.51.0-py2.py3-none-any.whl (432 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.6/432.6 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_videointelligence-2.14.1-py2.py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_vision-3.8.1-py2.py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.9/486.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
            "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
            "Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: google-apitools, crcmod, dill, hdfs, pyfarmhash, rouge-score, docopt\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131014 sha256=e336fa24fc7d202d06a974ac71515a7881a8da2a99f6179f0066d5bca9938bfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31403 sha256=f2928d47ae1f6100e433eecd4f0320038f682fd58dd744c9d3e0e3db559e151d\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=babd77ac7e8e9ad66b90a609c57e2ba7118941aec7c46700d0662dacf594ef2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=b4e3e86cff22c8311ee0c3b18baa5d691fcab9e8efe5c63fd6cb0d24c355d05b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=88658 sha256=939d956d26e2740019eca641ff617ecbbda1633d7b50164f74771b6a45d6b6b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=19fa97903f78a389290c307bd94be34dd671e9b31a9a18bb540e6c909b4b004a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=be76883e1bc1ad3c9c0ec97c47802cdefd01dffa3e60f5e9850789fb451766fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built google-apitools crcmod dill hdfs pyfarmhash rouge-score docopt\n",
            "Installing collected packages: sortedcontainers, pyfarmhash, kt-legacy, docopt, crcmod, zstandard, wrapt, uritemplate, tensorflow-estimator, scipy, redis, pydot, pyarrow, protobuf, portalocker, overrides, objsize, ml-dtypes, keras, jsonpickle, jedi, grpcio, fasteners, fastavro, dnspython, dill, colorama, cloudpickle, attrs, tensorflow-metadata, tensorflow-hub, sacrebleu, rouge-score, pymongo, pandas, ml-metadata, keras-tuner, hdfs, grpc-interceptor, docker, kubernetes, keyrings.google-artifactregistry-auth, grpcio-status, google-apitools, tensorboard, google-api-python-client, tensorflow, ml-pipelines-sdk, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-dlp, apache-beam, tensorflow-serving-api, google-cloud-pubsublite, tfx-bsl, tensorflow-transform, tensorflow-data-validation, tensorflow-model-analysis, tfx\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.3\n",
            "    Uninstalling pydot-3.0.3:\n",
            "      Successfully uninstalled pydot-3.0.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.0\n",
            "    Uninstalling jsonpickle-4.0.0:\n",
            "      Successfully uninstalled jsonpickle-4.0.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.13.1\n",
            "    Uninstalling tensorflow-metadata-1.13.1:\n",
            "      Successfully uninstalled tensorflow-metadata-1.13.1\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.16.1\n",
            "    Uninstalling tensorflow-hub-0.16.1:\n",
            "      Successfully uninstalled tensorflow-hub-0.16.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.62.3\n",
            "    Uninstalling grpcio-status-1.62.3:\n",
            "      Successfully uninstalled grpcio-status-1.62.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.151.0\n",
            "    Uninstalling google-api-python-client-2.151.0:\n",
            "      Successfully uninstalled google-api-python-client-2.151.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.61.0 attrs-23.2.0 cloudpickle-2.2.1 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docker-4.4.4 docopt-0.6.2 fastavro-1.9.7 fasteners-0.19 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-dlp-3.25.1 google-cloud-pubsublite-1.11.1 google-cloud-recommendations-ai-0.10.14 google-cloud-spanner-3.51.0 google-cloud-storage-2.19.0 google-cloud-videointelligence-2.14.1 google-cloud-vision-3.8.1 grpc-interceptor-0.15.4 grpcio-1.65.5 grpcio-status-1.48.2 hdfs-2.7.3 jedi-0.19.2 jsonpickle-3.4.2 keras-2.15.0 keras-tuner-1.4.7 keyrings.google-artifactregistry-auth-1.1.2 kt-legacy-1.0.5 kubernetes-12.0.1 ml-dtypes-0.3.2 ml-metadata-1.15.0 ml-pipelines-sdk-1.15.1 objsize-0.7.0 overrides-7.7.0 pandas-1.5.3 portalocker-3.0.0 protobuf-3.20.3 pyarrow-10.0.1 pydot-1.4.2 pyfarmhash-0.3.2 pymongo-4.10.1 redis-5.2.1 rouge-score-0.1.2 sacrebleu-2.4.3 scipy-1.12.0 sortedcontainers-2.4.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-data-validation-1.15.1 tensorflow-estimator-2.15.0 tensorflow-hub-0.15.0 tensorflow-metadata-1.15.0 tensorflow-model-analysis-0.46.0 tensorflow-serving-api-2.15.1 tensorflow-transform-1.15.0 tfx-1.15.1 tfx-bsl-1.15.1 uritemplate-3.0.1 wrapt-1.14.1 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "a89e22ce5ef94575801f612ddfe9d37c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autopep8\n",
            "  Downloading autopep8-2.3.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pycodestyle>=2.12.0 (from autopep8)\n",
            "  Downloading pycodestyle-2.12.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8) (2.2.1)\n",
            "Downloading autopep8-2.3.1-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycodestyle-2.12.1-py2.py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pycodestyle, autopep8\n",
            "Successfully installed autopep8-2.3.1 pycodestyle-2.12.1\n",
            "Collecting pylint\n",
            "  Downloading pylint-3.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: dill>=0.2 in /usr/local/lib/python3.10/dist-packages (from pylint) (0.3.1.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint) (4.3.6)\n",
            "Collecting astroid<=3.4.0-dev0,>=3.3.5 (from pylint)\n",
            "  Downloading astroid-3.3.6-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting isort!=5.13.0,<6,>=4.2.5 (from pylint)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mccabe<0.8,>=0.6 (from pylint)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint) (2.2.1)\n",
            "Collecting tomlkit>=0.10.1 (from pylint)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from astroid<=3.4.0-dev0,>=3.3.5->pylint) (4.12.2)\n",
            "Downloading pylint-3.3.2-py3-none-any.whl (521 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.9/521.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astroid-3.3.6-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.6/274.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: tomlkit, mccabe, isort, astroid, pylint\n",
            "Successfully installed astroid-3.3.6 isort-5.13.2 mccabe-0.7.0 pylint-3.3.2 tomlkit-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tfx\n",
        "!pip install autopep8\n",
        "!pip install pylint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DcId0xJNopw",
        "outputId": "065de158-de8b-41d8-e33d-41bbf720b937"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the .kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move kaggle.json to the .kaggle directory\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB-LgAsWNpTD",
        "outputId": "2eca610c-6e7e-4b2e-dd46-21673a05af34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dineshpiyasamara/sentiment-analysis-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyHFXd8HNy2h",
        "outputId": "9adbc5f7-6115-4546-fd8b-346f8dcc14f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/dineshpiyasamara/sentiment-analysis-dataset\n",
            "License(s): unknown\n",
            "Downloading sentiment-analysis-dataset.zip to /content\n",
            "  0% 0.00/460k [00:00<?, ?B/s]\n",
            "100% 460k/460k [00:00<00:00, 78.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!unzip sentiment-analysis-dataset.zip -d data\n",
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r2NlJ42N2nz",
        "outputId": "c7be2d60-9068-45fc-8a8e-0df955ed7bb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sentiment-analysis-dataset.zip\n",
            "  inflating: data/sentiment_analysis.csv  \n",
            "sentiment_analysis.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir modules"
      ],
      "metadata": {
        "id": "Acbzx2CQOQ_Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menjalankan sistem Machine Learning"
      ],
      "metadata": {
        "id": "BQhTL--V9GMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COMPONENTS_FILE = \"modules/components.py\"\n",
        "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
        "TRAINER_MODULE_FILE =  \"modules/trainer.py\"\n",
        "PIPELINES = \"local_pipeline.py\"\n",
        "TUNER_MODULE_FILE = \"modules/tuner.py\""
      ],
      "metadata": {
        "id": "HnigsJPyOTYp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {TUNER_MODULE_FILE}\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from typing import NamedTuple, Dict, Text, Any\n",
        "from keras_tuner.engine import base_tuner\n",
        "from tensorflow.keras import layers\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "LABEL_KEY = \"label\"\n",
        "FEATURE_KEY = \"tweet\"\n",
        "NUM_EPOCHS = 2\n",
        "\n",
        "TunerFnResult = NamedTuple(\"TunerFnResult\", [\n",
        "    (\"tuner\", base_tuner.BaseTuner),\n",
        "    (\"fit_kwargs\", Dict[Text, Any]),\n",
        "])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "monitor='binary_accuracy',  # Monitoring the binary accuracy\n",
        "patience=3,  # Number of epochs with no improvement after which training will be stopped\n",
        "min_delta=0.01,  # Minimum change in the monitored quantity to qualify as an improvement\n",
        "mode='max',  # Mode should be 'max' since we want to maximize the accuracy\n",
        "baseline=0.85  # Stop training once the accuracy reaches 85%\n",
        ")\n",
        "\n",
        "def transformed_name(key):\n",
        "    return f\"{key}_xf\"\n",
        "\n",
        "\n",
        "def gzip_reader_fn(filenames):\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
        "\n",
        "\n",
        "def input_fn(file_pattern, tf_transform_output, num_epochs, batch_size=64):\n",
        "    transform_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy()\n",
        "    )\n",
        "\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transform_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        num_epochs=num_epochs,\n",
        "        label_key=transformed_name(LABEL_KEY),\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def model_builder(hp, vectorizer_layer):\n",
        "    num_hidden_layers = hp.Choice(\n",
        "        \"num_hidden_layers\", values=[1, 2]\n",
        "    )\n",
        "    embed_dims = hp.Int(\n",
        "        \"embed_dims\", min_value=16, max_value=128, step=32\n",
        "    )\n",
        "    lstm_units= hp.Int(\n",
        "        \"lstm_units\", min_value=32, max_value=128, step=32\n",
        "    )\n",
        "    dense_units = hp.Int(\n",
        "        \"dense_units\", min_value=32, max_value=256, step=32\n",
        "    )\n",
        "    dropout_rate = hp.Float(\n",
        "        \"dropout_rate\", min_value=0.1, max_value=0.5, step=0.1\n",
        "    )\n",
        "    learning_rate = hp.Choice(\n",
        "        \"learning_rate\", values=[1e-2, 1e-3, 1e-4]\n",
        "    )\n",
        "\n",
        "    inputs = tf.keras.Input(\n",
        "        shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string\n",
        "    )\n",
        "\n",
        "    x = vectorizer_layer(inputs)\n",
        "    x = layers.Embedding(input_dim=5000, output_dim=embed_dims)(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(lstm_units))(x)\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        x = layers.Dense(dense_units, activation=tf.nn.relu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        metrics=[\"binary_accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def tuner_fn(fn_args: FnArgs):\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "    train_set = input_fn(\n",
        "        fn_args.train_files[0], tf_transform_output, NUM_EPOCHS\n",
        "    )\n",
        "    eval_set = input_fn(\n",
        "        fn_args.eval_files[0], tf_transform_output, NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    vectorizer_dataset = train_set.map(\n",
        "        lambda f, l: f[transformed_name(FEATURE_KEY)]\n",
        "    )\n",
        "\n",
        "    vectorizer_layer = layers.TextVectorization(\n",
        "        max_tokens=5000,\n",
        "        output_mode=\"int\",\n",
        "        output_sequence_length=500,\n",
        "    )\n",
        "    vectorizer_layer.adapt(vectorizer_dataset)\n",
        "\n",
        "    def wrapped_model_builder(hp):\n",
        "        # Wrap the `model_builder` to include `vectorizer_layer`\n",
        "        return model_builder(hp, vectorizer_layer)\n",
        "\n",
        "    hp = kt.HyperParameters()\n",
        "    hp.Choice('learning_rate', [1e-1, 1e-3])\n",
        "    hp.Int('num_layers', 1, 5)\n",
        "\n",
        "    tuner = kt.RandomSearch(\n",
        "        wrapped_model_builder,  # Use the wrapper function\n",
        "        max_trials=NUM_EPOCHS,\n",
        "        hyperparameters=hp,\n",
        "        allow_new_entries=True,\n",
        "        objective='val_accuracy',\n",
        "        directory=fn_args.working_dir,\n",
        "        project_name='test'\n",
        "    )\n",
        "    return TunerFnResult(\n",
        "        tuner=tuner,\n",
        "        fit_kwargs={\n",
        "            \"callbacks\": [early_stopping_callback],\n",
        "            \"x\": train_set,\n",
        "            \"validation_data\": eval_set,\n",
        "            \"steps_per_epoch\": fn_args.train_steps,\n",
        "            \"validation_steps\": fn_args.eval_steps,\n",
        "        },\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNfwlOrmU_m8",
        "outputId": "859f976c-5986-43e4-bb2f-02940fda2532"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting modules/tuner.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile {COMPONENTS_FILE}\n",
        "import os\n",
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "from tfx.components import (\n",
        "    CsvExampleGen,\n",
        "    StatisticsGen,\n",
        "    SchemaGen,\n",
        "    ExampleValidator,\n",
        "    Transform,\n",
        "    Trainer,\n",
        "    Evaluator,\n",
        "    Pusher,\n",
        "    Tuner\n",
        ")\n",
        "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2\n",
        "from tfx.types import Channel\n",
        "from tfx.dsl.components.common.resolver import Resolver\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n",
        "    LatestBlessedModelStrategy\n",
        ")\n",
        "\n",
        "\n",
        "def init_components(\n",
        "    data_dir,\n",
        "    transform_module,\n",
        "    training_module,\n",
        "    training_steps,\n",
        "    eval_steps,\n",
        "    serving_model_dir,\n",
        "):\n",
        "    \"\"\"\n",
        "    Initializes and configures TFX components for building a pipeline\n",
        "    to train and deploy a machine learning model.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Path to the directory containing input data for the pipeline.\n",
        "        transform_module (str): Path to the Python module implementing data transformation logic.\n",
        "        training_module (str): Path to the Python module defining the model training logic.\n",
        "        training_steps (int): Number of steps to execute during model training.\n",
        "        eval_steps (int): Number of steps to execute during model evaluation.\n",
        "        serving_model_dir (str): Path to the directory where the trained model will be exported for deployment.\n",
        "    \"\"\"\n",
        "\n",
        "    output = example_gen_pb2.Output(\n",
        "        split_config=example_gen_pb2.SplitConfig(splits=[\n",
        "            example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=8),\n",
        "            example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=2)\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    example_gen = CsvExampleGen(\n",
        "        input_base=data_dir,\n",
        "        output_config=output\n",
        "    )\n",
        "\n",
        "    statistics_gen = StatisticsGen(\n",
        "        examples=example_gen.outputs['examples']\n",
        "    )\n",
        "\n",
        "    schema_gen = SchemaGen(\n",
        "        statistics=statistics_gen.outputs[\"statistics\"]\n",
        "    )\n",
        "\n",
        "    example_validator = ExampleValidator(\n",
        "        statistics=statistics_gen.outputs['statistics'],\n",
        "        schema=schema_gen.outputs['schema']\n",
        "    )\n",
        "\n",
        "    transform = Transform(\n",
        "        examples=example_gen.outputs['examples'],\n",
        "        schema=schema_gen.outputs['schema'],\n",
        "        module_file=os.path.abspath(transform_module)\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        module_file=os.path.abspath(training_module),\n",
        "        examples=transform.outputs['transformed_examples'],\n",
        "        transform_graph=transform.outputs['transform_graph'],\n",
        "        schema=schema_gen.outputs['schema'],\n",
        "        train_args=trainer_pb2.TrainArgs(\n",
        "            splits=['train'],\n",
        "            num_steps=training_steps\n",
        "        ),\n",
        "        eval_args=trainer_pb2.EvalArgs(\n",
        "            splits=['eval'],\n",
        "            num_steps=eval_steps\n",
        "        )\n",
        "    )\n",
        "\n",
        "    model_resolver = Resolver(\n",
        "        strategy_class=LatestBlessedModelStrategy,\n",
        "        model=Channel(type=Model),\n",
        "        model_blessing=Channel(type=ModelBlessing)\n",
        "    ).with_id('Latest_blessed_model_resolver')\n",
        "\n",
        "    eval_config = tfma.EvalConfig(\n",
        "        model_specs=[tfma.ModelSpec(label_key='label')],\n",
        "        slicing_specs=[tfma.SlicingSpec()],\n",
        "        metrics_specs=[\n",
        "            tfma.MetricsSpec(metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='AUC'),\n",
        "                tfma.MetricConfig(class_name='FalsePositives'),\n",
        "                tfma.MetricConfig(class_name='TruePositives'),\n",
        "                tfma.MetricConfig(class_name='FalseNegatives'),\n",
        "                tfma.MetricConfig(class_name='TrueNegatives'),\n",
        "                tfma.MetricConfig(class_name='BinaryAccuracy',\n",
        "                    threshold=tfma.MetricThreshold(\n",
        "                        value_threshold=tfma.GenericValueThreshold(\n",
        "                            lower_bound={'value': 0.5}\n",
        "                        ),\n",
        "                        change_threshold=tfma.GenericChangeThreshold(\n",
        "                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                            absolute={'value': 0.0001}\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            ])\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    evaluator = Evaluator(\n",
        "        examples=example_gen.outputs['examples'],\n",
        "        model=trainer.outputs['model'],\n",
        "        baseline_model=model_resolver.outputs['model'],\n",
        "        eval_config=eval_config\n",
        "    )\n",
        "\n",
        "    pusher = Pusher(\n",
        "        model=trainer.outputs[\"model\"],\n",
        "        model_blessing=evaluator.outputs[\"blessing\"],\n",
        "        push_destination=pusher_pb2.PushDestination(\n",
        "            filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "                base_directory=serving_model_dir\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    tuner = Tuner(\n",
        "        module_file=os.path.abspath(\"modules/tuner.py\"),\n",
        "        examples=transform.outputs[\"transformed_examples\"],\n",
        "        transform_graph=transform.outputs[\"transform_graph\"],\n",
        "        schema=schema_gen.outputs[\"schema\"],\n",
        "        train_args=trainer_pb2.TrainArgs(splits=[\"train\"], num_steps=training_steps),\n",
        "        eval_args=trainer_pb2.EvalArgs(splits=[\"eval\"], num_steps=eval_steps),\n",
        "    )\n",
        "\n",
        "\n",
        "    components = (\n",
        "        example_gen,\n",
        "        statistics_gen,\n",
        "        schema_gen,\n",
        "        example_validator,\n",
        "        transform,\n",
        "        tuner,\n",
        "        trainer,\n",
        "        model_resolver,\n",
        "        evaluator,\n",
        "        pusher\n",
        "    )\n",
        "\n",
        "    return components"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo8UZgUCOVbQ",
        "outputId": "2b82d9bd-f30a-42c4-bbf4-c1142ede534f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting modules/components.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {TRAINER_MODULE_FILE}\n",
        "\n",
        "\"\"\"\n",
        "This module contains functions for training a sentiment analysis model using TensorFlow and TensorFlow Transform.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow.keras import layers\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "\n",
        "# Define constants\n",
        "LABEL_KEY = \"label\"\n",
        "FEATURE_KEY = \"tweet\"\n",
        "EMBEDDING_DIM = 32\n",
        "\n",
        "# Function to rename transformed features\n",
        "def transformed_name(key):\n",
        "    \"\"\"\n",
        "    Transform the given key.\n",
        "\n",
        "    Args:\n",
        "        key (str): Input key to transform.\n",
        "\n",
        "    Returns:\n",
        "        str: Transformed key.\n",
        "    \"\"\"\n",
        "    return key + \"_xf\"\n",
        "\n",
        "# Function to read data from compressed TFRecord files\n",
        "def gzip_reader_fn(filenames):\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "# Input function to create transformed features and batch data\n",
        "def input_fn(file_pattern, tf_transform_output, num_epochs, batch_size=64):\n",
        "    \"\"\"\n",
        "    Create input function for training data.\n",
        "\n",
        "    Args:\n",
        "        file_pattern (str): File pattern for input data.\n",
        "        tf_transform_output (tensorflow_transform.TFTransformOutput): TensorFlow Transform output.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        batch_size (int): Batch size.\n",
        "\n",
        "    Returns:\n",
        "        tf.data.Dataset: Input dataset.\n",
        "    \"\"\"\n",
        "    transform_feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transform_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        num_epochs=num_epochs,\n",
        "        label_key=transformed_name(LABEL_KEY)\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Text vectorization layer for tokenization and data standardization\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=100\n",
        ")\n",
        "\n",
        "# Function to build the machine learning model\n",
        "def model_builder():\n",
        "    \"\"\"\n",
        "    Build the machine learning model.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: Compiled Keras model.\n",
        "    \"\"\"\n",
        "    inputs = tf.keras.Input(shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string)\n",
        "    reshaped_input = tf.reshape(inputs, [-1])\n",
        "    x = vectorize_layer(reshaped_input)\n",
        "    x = layers.Embedding(10000, EMBEDDING_DIM, name=\"embedding\")(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Function to preprocess raw request data for deployment\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "    \"\"\"\n",
        "    Get serving function for TensorFlow Serving.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): Trained Keras model.\n",
        "        tf_transform_output (tensorflow_transform.TFTransformOutput): TensorFlow Transform output.\n",
        "\n",
        "    Returns:\n",
        "        Callable: Serve function for TensorFlow Serving.\n",
        "    \"\"\"\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "        feature_spec.pop(LABEL_KEY)\n",
        "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "        return model(transformed_features)\n",
        "\n",
        "    return serve_tf_examples_fn\n",
        "\n",
        "# Function to run the training process\n",
        "def run_fn(fn_args: FnArgs) -> None:\n",
        "    \"\"\"\n",
        "    Run the training process.\n",
        "\n",
        "    Args:\n",
        "        fn_args (FnArgs): Function arguments.\n",
        "    \"\"\"\n",
        "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir, update_freq='batch'\n",
        "    )\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_binary_accuracy', mode='max', verbose=1, patience=10\n",
        "    )\n",
        "    mc = tf.keras.callbacks.ModelCheckpoint(\n",
        "        fn_args.serving_model_dir, monitor='val_binary_accuracy', mode='max', verbose=1, save_best_only=True\n",
        "    )\n",
        "\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "    train_set = input_fn(fn_args.train_files, tf_transform_output, 10)\n",
        "    val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)\n",
        "    vectorize_layer.adapt(\n",
        "        [j[0].numpy()[0] for j in [i[0][transformed_name(FEATURE_KEY)] for i in list(train_set)]]\n",
        "    )\n",
        "\n",
        "    model = model_builder()\n",
        "\n",
        "    model.fit(\n",
        "        x=train_set,\n",
        "        validation_data=val_set,\n",
        "        callbacks=[tensorboard_callback, es, mc],\n",
        "        steps_per_epoch=1000,\n",
        "        validation_steps=1000,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    signatures = {\n",
        "        'serving_default':\n",
        "        _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
        "            tf.TensorSpec(\n",
        "                shape=[None],\n",
        "                dtype=tf.string,\n",
        "                name='examples'\n",
        "            )\n",
        "        )\n",
        "    }\n",
        "    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaKB6sAHOsof",
        "outputId": "0f47eca4-fe04-4bcb-a935-774c2aa15cfa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing modules/trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {TRANSFORM_MODULE_FILE}\n",
        "\n",
        "\"\"\"\n",
        "Process of transforming sentiment data.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "LABEL_KEY_NEW = \"label\"\n",
        "FEATURE_KEY_NEW = \"tweet\"\n",
        "\n",
        "def transformed_name(key):\n",
        "    \"\"\"\n",
        "    Transform the given key.\n",
        "\n",
        "    Args:\n",
        "        key (str): Input key to transform.\n",
        "\n",
        "    Returns:\n",
        "        str: Transformed key.\n",
        "    \"\"\"\n",
        "    return key + \"_xf\"\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"\n",
        "    Preprocess input data.\n",
        "\n",
        "    Args:\n",
        "        inputs (dict): Input data dictionary containing 'label' and 'tweet' keys.\n",
        "\n",
        "    Returns:\n",
        "        dict: Transformed output data dictionary.\n",
        "    \"\"\"\n",
        "    outputs = {}\n",
        "    print(inputs[FEATURE_KEY_NEW])\n",
        "    outputs[transformed_name(LABEL_KEY_NEW)] = tf.cast(inputs[LABEL_KEY_NEW], tf.int64)\n",
        "    outputs[transformed_name(FEATURE_KEY_NEW)] = tf.strings.lower(inputs[FEATURE_KEY_NEW])\n",
        "    return outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf0BBGytOxKx",
        "outputId": "e3357be4-cd91-4ed5-9d69-630a0aeba671"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing modules/transform.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {PIPELINES}\n",
        "import os\n",
        "from typing import Text\n",
        "\n",
        "from absl import logging\n",
        "from tfx.orchestration import metadata, pipeline\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "\n",
        "PIPELINE_NAME = 'sentiment-pipeline'\n",
        "\n",
        "DATA_ROOT = 'data'\n",
        "TRANSFORM_MODULE_FILE = 'modules/transform.py'\n",
        "TRAINER_MODULE_FILE = 'modules/trainer.py'\n",
        "TUNER_MODULE_FILE = 'modules/tuner.py'\n",
        "\n",
        "OUTPUT_BASE = 'output'\n",
        "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
        "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
        "metadata_path = os.path.join(pipeline_root, 'metadata.sqlite')\n",
        "\n",
        "\n",
        "def init_local_pipeline(\n",
        "    components, pipeline_root: Text\n",
        ") -> pipeline.Pipeline:\n",
        "    \"\"\"\n",
        "    Initialize a local TFX pipeline.\n",
        "\n",
        "    Args:\n",
        "        components: A dictionary of TFX components to be included in the pipeline.\n",
        "        pipeline_root: Root directory for pipeline output artifacts.\n",
        "\n",
        "    Returns:\n",
        "        A TFX pipeline.\n",
        "    \"\"\"\n",
        "    logging.info(f'Pipeline root set to: {pipeline_root}')\n",
        "\n",
        "    return pipeline.Pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=pipeline_root,\n",
        "        components=components,\n",
        "        enable_cache=True,\n",
        "        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
        "            metadata_path\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logging.set_verbosity(logging.INFO)\n",
        "\n",
        "    from modules.components import init_components\n",
        "    components = init_components(\n",
        "        DATA_ROOT,\n",
        "        training_module=TRAINER_MODULE_FILE,\n",
        "        transform_module=TRANSFORM_MODULE_FILE,\n",
        "        training_steps=100,\n",
        "        eval_steps=50,\n",
        "        serving_model_dir=serving_model_dir,\n",
        "    )\n",
        "\n",
        "    pipeline = init_local_pipeline(components, pipeline_root)\n",
        "    BeamDagRunner().run(pipeline=pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJWSNsOYOzzs",
        "outputId": "3e36fcf3-655c-4412-d2e6-1f07104ad1a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting local_pipeline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python local_pipeline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA_fba7vO4cC",
        "outputId": "dbecf178-9975-4487-dad8-5252f830e396"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "      filename_uri: \"output/sentiment-pipeline/metadata.sqlite\"\n",
            "      connection_mode: READWRITE_OPENCREATE\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using connection config:\n",
            " sqlite {\n",
            "  filename_uri: \"output/sentiment-pipeline/metadata.sqlite\"\n",
            "  connection_mode: READWRITE_OPENCREATE\n",
            "}\n",
            "\n",
            "INFO:absl:Node CsvExampleGen depends on [].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node CsvExampleGen is scheduled.\n",
            "INFO:absl:Node Latest_blessed_model_resolver depends on [].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Latest_blessed_model_resolver is scheduled.\n",
            "INFO:absl:Node StatisticsGen depends on ['Run[CsvExampleGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node StatisticsGen is scheduled.\n",
            "INFO:absl:Node SchemaGen depends on ['Run[StatisticsGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node SchemaGen is scheduled.\n",
            "INFO:absl:Node ExampleValidator depends on ['Run[SchemaGen]', 'Run[StatisticsGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node ExampleValidator is scheduled.\n",
            "INFO:absl:Node Transform depends on ['Run[CsvExampleGen]', 'Run[SchemaGen]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Transform is scheduled.\n",
            "INFO:absl:Node Trainer depends on ['Run[SchemaGen]', 'Run[Transform]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Trainer is scheduled.\n",
            "INFO:absl:Node Tuner depends on ['Run[SchemaGen]', 'Run[Transform]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Tuner is scheduled.\n",
            "INFO:absl:Node Evaluator depends on ['Run[CsvExampleGen]', 'Run[Latest_blessed_model_resolver]', 'Run[Trainer]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Evaluator is scheduled.\n",
            "INFO:absl:Node Pusher depends on ['Run[Evaluator]', 'Run[Trainer]'].\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "INFO:absl:Node Pusher is scheduled.\n",
            "INFO:absl:node CsvExampleGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"data\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 8,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_file_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 5\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:[CsvExampleGen] Resolved inputs: ({},)\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:A cached execution 34 is used.\n",
            "INFO:absl:node CsvExampleGen is finished.\n",
            "INFO:absl:node Latest_blessed_model_resolver is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
            "  }\n",
            "  id: \"Latest_blessed_model_resolver\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Latest_blessed_model_resolver\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"_generated_model_3\"\n",
            "    value {\n",
            "      channels {\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      hidden: true\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"_generated_modelblessing_4\"\n",
            "    value {\n",
            "      channels {\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ModelBlessing\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      hidden: true\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      input_graph_ref {\n",
            "        graph_id: \"graph_1\"\n",
            "        key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model_blessing\"\n",
            "    value {\n",
            "      input_graph_ref {\n",
            "        graph_id: \"graph_1\"\n",
            "        key: \"model_blessing\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  input_graphs {\n",
            "    key: \"graph_1\"\n",
            "    value {\n",
            "      nodes {\n",
            "        key: \"dict_2\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_MULTIMAP\n",
            "          dict_node {\n",
            "            node_ids {\n",
            "              key: \"model\"\n",
            "              value: \"input_3\"\n",
            "            }\n",
            "            node_ids {\n",
            "              key: \"model_blessing\"\n",
            "              value: \"input_4\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      nodes {\n",
            "        key: \"input_3\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_LIST\n",
            "          input_node {\n",
            "            input_key: \"_generated_model_3\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      nodes {\n",
            "        key: \"input_4\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_LIST\n",
            "          input_node {\n",
            "            input_key: \"_generated_modelblessing_4\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      nodes {\n",
            "        key: \"op_1\"\n",
            "        value {\n",
            "          output_data_type: ARTIFACT_MULTIMAP\n",
            "          op_node {\n",
            "            op_type: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
            "            args {\n",
            "              node_id: \"dict_2\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      result_node: \"op_1\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Evaluator\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Running as an resolver node.\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Latest_blessed_model_resolver] Resolved inputs: ({'model_blessing': [], 'model': []},)\n",
            "INFO:absl:node Latest_blessed_model_resolver is finished.\n",
            "INFO:absl:node StatisticsGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
            "    base_type: PROCESS\n",
            "  }\n",
            "  id: \"StatisticsGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.StatisticsGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"SchemaGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:1100229,xor_checksum:1683653538,sum_checksum:1683653538\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733735157487\n",
            "last_update_time_since_epoch: 1733735157487\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:A cached execution 36 is used.\n",
            "INFO:absl:node StatisticsGen is finished.\n",
            "INFO:absl:node SchemaGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
            "    base_type: PROCESS\n",
            "  }\n",
            "  id: \"SchemaGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "            base_type: STATISTICS\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"infer_feature_shape\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "downstream_nodes: \"ExampleValidator\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Transform\"\n",
            "downstream_nodes: \"Tuner\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 18\n",
            "uri: \"output/sentiment-pipeline/StatisticsGen/statistics/3\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"stats_dashboard_link\"\n",
            "  value {\n",
            "    string_value: \"\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ExampleStatistics\"\n",
            "create_time_since_epoch: 1733735163703\n",
            "last_update_time_since_epoch: 1733735163703\n",
            ", artifact_type: id: 18\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:A cached execution 37 is used.\n",
            "INFO:absl:node SchemaGen is finished.\n",
            "INFO:absl:node ExampleValidator is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
            "  }\n",
            "  id: \"ExampleValidator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.ExampleValidator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"statistics\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"StatisticsGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.StatisticsGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ExampleStatistics\"\n",
            "            base_type: STATISTICS\n",
            "          }\n",
            "        }\n",
            "        output_key: \"statistics\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"exclude_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"[]\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"StatisticsGen\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[ExampleValidator] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\n",
            "type_id: 18\n",
            "uri: \"output/sentiment-pipeline/StatisticsGen/statistics/3\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"stats_dashboard_link\"\n",
            "  value {\n",
            "    string_value: \"\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ExampleStatistics\"\n",
            "create_time_since_epoch: 1733735163703\n",
            "last_update_time_since_epoch: 1733735163703\n",
            ", artifact_type: id: 18\n",
            "name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:A cached execution 38 is used.\n",
            "INFO:absl:node ExampleValidator is finished.\n",
            "INFO:absl:node Transform is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.transform.component.Transform\"\n",
            "    base_type: TRANSFORM\n",
            "  }\n",
            "  id: \"Transform\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Transform\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"post_transform_anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformGraph\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transformed_examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"updated_analyzer_cache\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformCache\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"disable_statistics\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"force_tf_compat_v1\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"transform@output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Tuner\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Transform] Resolved inputs: ({'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")], 'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:1100229,xor_checksum:1683653538,sum_checksum:1683653538\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733735157487\n",
            "last_update_time_since_epoch: 1733735157487\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 39\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1733738906.617035   17988 chttp2_server.cc:1023] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {created_time:\"2024-12-09T10:08:26.617014249+00:00\", children:[UNKNOWN:socket: Address family not supported by protocol (97) {created_time:\"2024-12-09T10:08:26.616981824+00:00\"}]}\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=39, input_dict={'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")], 'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:1100229,xor_checksum:1683653538,sum_checksum:1683653538\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733735157487\n",
            "last_update_time_since_epoch: 1733735157487\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'transform_graph': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/transform_graph/39\"\n",
            ", artifact_type: name: \"TransformGraph\"\n",
            ")], 'pre_transform_stats': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/pre_transform_stats/39\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/updated_analyzer_cache/39\"\n",
            ", artifact_type: name: \"TransformCache\"\n",
            ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/post_transform_anomalies/39\"\n",
            ", artifact_type: name: \"ExampleAnomalies\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")], 'post_transform_stats': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/post_transform_stats/39\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'pre_transform_schema': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/pre_transform_schema/39\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")], 'transformed_examples': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/transformed_examples/39\"\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'post_transform_schema': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/post_transform_schema/39\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")]}), exec_properties={'force_tf_compat_v1': 0, 'custom_config': 'null', 'module_path': 'transform@output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl', 'disable_statistics': 0}, execution_output_uri='output/sentiment-pipeline/Transform/.system/executor_execution/39/executor_output.pb', stateful_working_dir='output/sentiment-pipeline/Transform/.system/stateful_working_dir/26079226-3c4c-4230-8abe-4a01650cef89', tmp_dir='output/sentiment-pipeline/Transform/.system/executor_execution/39/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.transform.component.Transform\"\n",
            "    base_type: TRANSFORM\n",
            "  }\n",
            "  id: \"Transform\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Transform\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"post_transform_anomalies\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleAnomalies\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"post_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_schema\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Schema\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"pre_transform_stats\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ExampleStatistics\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          base_type: STATISTICS\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformGraph\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"transformed_examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "          base_type: DATASET\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"updated_analyzer_cache\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TransformCache\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"disable_statistics\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"force_tf_compat_v1\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"transform@output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "downstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Tuner\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"sentiment-pipeline\"\n",
            ", pipeline_run_id='20241209-100825.750396', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n",
            "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform@output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
            "INFO:absl:Installing 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmp3ooj68gi', 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl']\n",
            "Processing ./output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\n",
            "Installing collected packages: tfx-user-code-Transform\n",
            "Successfully installed tfx-user-code-Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b\n",
            "INFO:absl:Successfully installed 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'.\n",
            "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform@output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
            "INFO:absl:Installing 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpvm40wgwn', 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl']\n",
            "Processing ./output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\n",
            "Installing collected packages: tfx-user-code-Transform\n",
            "Successfully installed tfx-user-code-Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b\n",
            "INFO:absl:Successfully installed 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'.\n",
            "INFO:absl:Installing 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpufs3isj6', 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl']\n",
            "Processing ./output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\n",
            "Installing collected packages: tfx-user-code-Transform\n",
            "Successfully installed tfx-user-code-Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b\n",
            "INFO:absl:Successfully installed 'output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'.\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "Tensor(\"PlaceholderWithDefault_2:0\", shape=(None, 1), dtype=string)\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\n",
            "INFO:absl:Writing fingerprint to output/sentiment-pipeline/Transform/transform_graph/39/.temp_path/tftransform_tmp/153a132d82d44f92bce5be24da10e234/fingerprint.pb\n",
            "Tensor(\"PlaceholderWithDefault_2:0\", shape=(None, 1), dtype=string)\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 39 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir output/sentiment-pipeline/Transform/.system/stateful_working_dir/26079226-3c4c-4230-8abe-4a01650cef89\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'transform_graph': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/transform_graph/39\"\n",
            ", artifact_type: name: \"TransformGraph\"\n",
            ")], 'pre_transform_stats': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/pre_transform_stats/39\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/updated_analyzer_cache/39\"\n",
            ", artifact_type: name: \"TransformCache\"\n",
            ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/post_transform_anomalies/39\"\n",
            ", artifact_type: name: \"ExampleAnomalies\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            ")], 'post_transform_stats': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/post_transform_stats/39\"\n",
            ", artifact_type: name: \"ExampleStatistics\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "base_type: STATISTICS\n",
            ")], 'pre_transform_schema': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/pre_transform_schema/39\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")], 'transformed_examples': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/transformed_examples/39\"\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'post_transform_schema': [Artifact(artifact: uri: \"output/sentiment-pipeline/Transform/post_transform_schema/39\"\n",
            ", artifact_type: name: \"Schema\"\n",
            ")]}) for execution 39\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Transform is finished.\n",
            "INFO:absl:node Trainer is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "    base_type: TRAIN\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transformed_examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"TransformGraph\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transform_graph\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 50,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"trainer@output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 100,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"Transform\"\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Trainer] Resolved inputs: ({'examples': [Artifact(artifact: id: 45\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/Transform/transformed_examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"eval\\\", \\\"train\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733738929819\n",
            "last_update_time_since_epoch: 1733738929819\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")], 'transform_graph': [Artifact(artifact: id: 39\n",
            "type_id: 24\n",
            "uri: \"output/sentiment-pipeline/Transform/transform_graph/39\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"TransformGraph\"\n",
            "create_time_since_epoch: 1733738929818\n",
            "last_update_time_since_epoch: 1733738929818\n",
            ", artifact_type: id: 24\n",
            "name: \"TransformGraph\"\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 40\n",
            "I0000 00:00:1733738929.995957   17988 chttp2_server.cc:1023] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {created_time:\"2024-12-09T10:08:49.995948364+00:00\", children:[UNKNOWN:socket: Address family not supported by protocol (97) {created_time:\"2024-12-09T10:08:49.995935984+00:00\"}]}\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=40, input_dict={'examples': [Artifact(artifact: id: 45\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/Transform/transformed_examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"eval\\\", \\\"train\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733738929819\n",
            "last_update_time_since_epoch: 1733738929819\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")], 'transform_graph': [Artifact(artifact: id: 39\n",
            "type_id: 24\n",
            "uri: \"output/sentiment-pipeline/Transform/transform_graph/39\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"TransformGraph\"\n",
            "create_time_since_epoch: 1733738929818\n",
            "last_update_time_since_epoch: 1733738929818\n",
            ", artifact_type: id: 24\n",
            "name: \"TransformGraph\"\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"output/sentiment-pipeline/Trainer/model_run/40\"\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")], 'model': [Artifact(artifact: uri: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            ", artifact_type: name: \"Model\"\n",
            "base_type: MODEL\n",
            ")]}), exec_properties={'eval_args': '{\\n  \"num_steps\": 50,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'train_args': '{\\n  \"num_steps\": 100,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'custom_config': 'null', 'module_path': 'trainer@output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'}, execution_output_uri='output/sentiment-pipeline/Trainer/.system/executor_execution/40/executor_output.pb', stateful_working_dir='output/sentiment-pipeline/Trainer/.system/stateful_working_dir/0b3fabc1-45a2-4c33-8051-997dbe523ab2', tmp_dir='output/sentiment-pipeline/Trainer/.system/executor_execution/40/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "    base_type: TRAIN\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transformed_examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"TransformGraph\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transform_graph\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 50,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"trainer@output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 100,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"Transform\"\n",
            "downstream_nodes: \"Evaluator\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"sentiment-pipeline\"\n",
            ", pipeline_run_id='20241209-100825.750396', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:udf_utils.get_fn {'eval_args': '{\\n  \"num_steps\": 50,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'train_args': '{\\n  \"num_steps\": 100,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}', 'custom_config': 'null', 'module_path': 'trainer@output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'} 'run_fn'\n",
            "INFO:absl:Installing 'output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpir8ie_ms', 'output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl']\n",
            "Processing ./output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\n",
            "Installing collected packages: tfx-user-code-Trainer\n",
            "Successfully installed tfx-user-code-Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b\n",
            "INFO:absl:Successfully installed 'output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'.\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " tweet_xf (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " tf.reshape (TFOpLambda)     (None,)                   0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 100)               0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 32)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324225 (1.24 MB)\n",
            "Trainable params: 324225 (1.24 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " 986/1000 [============================>.] - ETA: 0s - loss: 0.1576 - binary_accuracy: 0.9319WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n",
            "\n",
            "Epoch 1: val_binary_accuracy improved from -inf to 0.86001, saving model to output/sentiment-pipeline/Trainer/model/40/Format-Serving\n",
            "INFO:absl:Function `_wrapped_model` contains input name(s) table_handle, 37055, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_none_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_37055, model_dense_2_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to output/sentiment-pipeline/Trainer/model/40/Format-Serving/fingerprint.pb\n",
            "1000/1000 [==============================] - 18s 17ms/step - loss: 0.1574 - binary_accuracy: 0.9320 - val_loss: 0.5144 - val_binary_accuracy: 0.8600\n",
            "INFO:absl:Feature id has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Function `serve_tf_examples_fn` contains input name(s) table_handle, 38132, resource with unsupported characters which will be renamed to model_text_vectorization_string_lookup_hash_table_lookup_lookuptablefindv2_table_handle, model_embedding_embedding_lookup_38132, model_dense_2_biasadd_readvariableop_resource in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "INFO:absl:Writing fingerprint to output/sentiment-pipeline/Trainer/model/40/Format-Serving/fingerprint.pb\n",
            "INFO:absl:Training complete. Model written to output/sentiment-pipeline/Trainer/model/40/Format-Serving. ModelRun written to output/sentiment-pipeline/Trainer/model_run/40\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 40 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir output/sentiment-pipeline/Trainer/.system/stateful_working_dir/0b3fabc1-45a2-4c33-8051-997dbe523ab2\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model_run': [Artifact(artifact: uri: \"output/sentiment-pipeline/Trainer/model_run/40\"\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")], 'model': [Artifact(artifact: uri: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            ", artifact_type: name: \"Model\"\n",
            "base_type: MODEL\n",
            ")]}) for execution 40\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Trainer is finished.\n",
            "INFO:absl:node Tuner is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.tuner.component.Tuner\"\n",
            "  }\n",
            "  id: \"Tuner\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Tuner\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transformed_examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"TransformGraph\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transform_graph\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"best_hyperparameters\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"HyperParameters\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"tuner_results\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TunerResults\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 50,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"tuner@output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 100,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Tuner] Resolved inputs: ({'transform_graph': [Artifact(artifact: id: 39\n",
            "type_id: 24\n",
            "uri: \"output/sentiment-pipeline/Transform/transform_graph/39\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"TransformGraph\"\n",
            "create_time_since_epoch: 1733738929818\n",
            "last_update_time_since_epoch: 1733738929818\n",
            ", artifact_type: id: 24\n",
            "name: \"TransformGraph\"\n",
            ")], 'examples': [Artifact(artifact: id: 45\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/Transform/transformed_examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"eval\\\", \\\"train\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733738929819\n",
            "last_update_time_since_epoch: 1733738929819\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 41\n",
            "I0000 00:00:1733738966.214379   17988 chttp2_server.cc:1023] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {created_time:\"2024-12-09T10:09:26.214370381+00:00\", children:[UNKNOWN:socket: Address family not supported by protocol (97) {created_time:\"2024-12-09T10:09:26.214357268+00:00\"}]}\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=41, input_dict={'transform_graph': [Artifact(artifact: id: 39\n",
            "type_id: 24\n",
            "uri: \"output/sentiment-pipeline/Transform/transform_graph/39\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"TransformGraph\"\n",
            "create_time_since_epoch: 1733738929818\n",
            "last_update_time_since_epoch: 1733738929818\n",
            ", artifact_type: id: 24\n",
            "name: \"TransformGraph\"\n",
            ")], 'examples': [Artifact(artifact: id: 45\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/Transform/transformed_examples/39\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"eval\\\", \\\"train\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733738929819\n",
            "last_update_time_since_epoch: 1733738929819\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'schema': [Artifact(artifact: id: 3\n",
            "type_id: 20\n",
            "uri: \"output/sentiment-pipeline/SchemaGen/schema/4\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Schema\"\n",
            "create_time_since_epoch: 1733735164017\n",
            "last_update_time_since_epoch: 1733735164017\n",
            ", artifact_type: id: 20\n",
            "name: \"Schema\"\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'tuner_results': [Artifact(artifact: uri: \"output/sentiment-pipeline/Tuner/tuner_results/41\"\n",
            ", artifact_type: name: \"TunerResults\"\n",
            ")], 'best_hyperparameters': [Artifact(artifact: uri: \"output/sentiment-pipeline/Tuner/best_hyperparameters/41\"\n",
            ", artifact_type: name: \"HyperParameters\"\n",
            ")]}), exec_properties={'eval_args': '{\\n  \"num_steps\": 50,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'custom_config': 'null', 'module_path': 'tuner@output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 100,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}'}, execution_output_uri='output/sentiment-pipeline/Tuner/.system/executor_execution/41/executor_output.pb', stateful_working_dir='output/sentiment-pipeline/Tuner/.system/stateful_working_dir/e42fef00-4b68-4baa-8e64-1e632d5ec7d9', tmp_dir='output/sentiment-pipeline/Tuner/.system/executor_execution/41/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.tuner.component.Tuner\"\n",
            "  }\n",
            "  id: \"Tuner\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Tuner\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transformed_examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"schema\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"SchemaGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.SchemaGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Schema\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"schema\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"transform_graph\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Transform\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Transform\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"TransformGraph\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"transform_graph\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"best_hyperparameters\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"HyperParameters\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"tuner_results\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"TunerResults\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 50,\\n  \\\"splits\\\": [\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"tuner@output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 100,\\n  \\\"splits\\\": [\\n    \\\"train\\\"\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"SchemaGen\"\n",
            "upstream_nodes: \"Transform\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"sentiment-pipeline\"\n",
            ", pipeline_run_id='20241209-100825.750396', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Creating temp directory at output/sentiment-pipeline/Tuner/.system/executor_execution/41/.temp/41/\n",
            "INFO:absl:udf_utils.get_fn {'eval_args': '{\\n  \"num_steps\": 50,\\n  \"splits\": [\\n    \"eval\"\\n  ]\\n}', 'custom_config': 'null', 'module_path': 'tuner@output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 100,\\n  \"splits\": [\\n    \"train\"\\n  ]\\n}'} 'tuner_fn'\n",
            "INFO:absl:Installing 'output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpoo32wi_n', 'output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl']\n",
            "Processing ./output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl\n",
            "Installing collected packages: tfx-user-code-Tuner\n",
            "Successfully installed tfx-user-code-Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b\n",
            "INFO:absl:Successfully installed 'output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl'.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature label_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature tweet_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "Search space summary\n",
            "Default search space size: 7\n",
            "learning_rate (Choice)\n",
            "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.001], 'ordered': True}\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "num_hidden_layers (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 2], 'ordered': True}\n",
            "embed_dims (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "lstm_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "dense_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "dropout_rate (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "INFO:absl:Start tuning... Tuner ID: tuner0\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "2                 |2                 |num_layers\n",
            "1                 |1                 |num_hidden_layers\n",
            "16                |16                |embed_dims\n",
            "64                |64                |lstm_units\n",
            "160               |160               |dense_units\n",
            "0.1               |0.1               |dropout_rate\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n",
            "100/100 [==============================] - 83s 764ms/step - loss: 0.5759 - binary_accuracy: 0.7786 - val_loss: 0.3284 - val_binary_accuracy: 0.8719\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 265, in _run_and_update_trial\n",
            "    tuner_utils.convert_to_metrics_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in convert_to_metrics_dict\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in <listcomp>\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 145, in convert_to_metrics_dict\n",
            "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 116, in _get_best_value_and_best_epoch_from_history\n",
            "    objective_value = objective.get_value(metrics)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/objective.py\", line 59, in get_value\n",
            "    return logs[self.name]\n",
            "KeyError: 'val_accuracy'\n",
            "Trial 1 Complete [00h 01m 29s]\n",
            "\n",
            "Best val_accuracy So Far: None\n",
            "Total elapsed time: 00h 01m 29s\n",
            "\n",
            "Search: Running Trial #2\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |learning_rate\n",
            "1                 |2                 |num_layers\n",
            "1                 |1                 |num_hidden_layers\n",
            "112               |16                |embed_dims\n",
            "32                |64                |lstm_units\n",
            "160               |160               |dense_units\n",
            "0.1               |0.1               |dropout_rate\n",
            "\n",
            "100/100 [==============================] - 81s 744ms/step - loss: 0.3921 - binary_accuracy: 0.8114 - val_loss: 0.2793 - val_binary_accuracy: 0.8908\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 265, in _run_and_update_trial\n",
            "    tuner_utils.convert_to_metrics_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in convert_to_metrics_dict\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in <listcomp>\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 145, in convert_to_metrics_dict\n",
            "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 116, in _get_best_value_and_best_epoch_from_history\n",
            "    objective_value = objective.get_value(metrics)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/objective.py\", line 59, in get_value\n",
            "    return logs[self.name]\n",
            "KeyError: 'val_accuracy'\n",
            "Trial 2 Complete [00h 01m 22s]\n",
            "\n",
            "Best val_accuracy So Far: None\n",
            "Total elapsed time: 00h 02m 51s\n",
            "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
            "Results summary\n",
            "Results in output/sentiment-pipeline/Tuner/.system/executor_execution/41/.temp/41/test\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.001\n",
            "num_layers: 2\n",
            "num_hidden_layers: 1\n",
            "embed_dims: 16\n",
            "lstm_units: 64\n",
            "dense_units: 160\n",
            "dropout_rate: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 265, in _run_and_update_trial\n",
            "    tuner_utils.convert_to_metrics_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in convert_to_metrics_dict\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in <listcomp>\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 145, in convert_to_metrics_dict\n",
            "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 116, in _get_best_value_and_best_epoch_from_history\n",
            "    objective_value = objective.get_value(metrics)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/objective.py\", line 59, in get_value\n",
            "    return logs[self.name]\n",
            "KeyError: 'val_accuracy'\n",
            "\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.001\n",
            "num_layers: 1\n",
            "num_hidden_layers: 1\n",
            "embed_dims: 112\n",
            "lstm_units: 32\n",
            "dense_units: 160\n",
            "dropout_rate: 0.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 265, in _run_and_update_trial\n",
            "    tuner_utils.convert_to_metrics_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in convert_to_metrics_dict\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 132, in <listcomp>\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 145, in convert_to_metrics_dict\n",
            "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\", line 116, in _get_best_value_and_best_epoch_from_history\n",
            "    objective_value = objective.get_value(metrics)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/objective.py\", line 59, in get_value\n",
            "    return logs[self.name]\n",
            "KeyError: 'val_accuracy'\n",
            "\n",
            "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.1, 'conditions': [], 'values': [0.1, 0.001], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'num_layers', 'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'num_hidden_layers', 'default': 1, 'conditions': [], 'values': [1, 2], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'embed_dims', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'lstm_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'dense_units', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}}, {'class_name': 'Float', 'config': {'name': 'dropout_rate', 'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}}], 'values': {'learning_rate': 0.001, 'num_layers': 2, 'num_hidden_layers': 1, 'embed_dims': 16, 'lstm_units': 64, 'dense_units': 160, 'dropout_rate': 0.1}}\n",
            "INFO:absl:Best Hyperparameters are written to output/sentiment-pipeline/Tuner/best_hyperparameters/41/best_hyperparameters.txt.\n",
            "INFO:absl:Tuner results are written to output/sentiment-pipeline/Tuner/tuner_results/41/tuner_results.json.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 41 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir output/sentiment-pipeline/Tuner/.system/stateful_working_dir/e42fef00-4b68-4baa-8e64-1e632d5ec7d9\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'tuner_results': [Artifact(artifact: uri: \"output/sentiment-pipeline/Tuner/tuner_results/41\"\n",
            ", artifact_type: name: \"TunerResults\"\n",
            ")], 'best_hyperparameters': [Artifact(artifact: uri: \"output/sentiment-pipeline/Tuner/best_hyperparameters/41\"\n",
            ", artifact_type: name: \"HyperParameters\"\n",
            ")]}) for execution 41\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Tuner is finished.\n",
            "INFO:absl:node Evaluator is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "    base_type: EVALUATE\n",
            "  }\n",
            "  id: \"Evaluator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Evaluator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"baseline_model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Latest_blessed_model_resolver\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Latest_blessed_model_resolver\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"blessing\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelBlessing\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"evaluation\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelEvaluation\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"eval_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalsePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TruePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalseNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TrueNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"label\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"example_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"fairness_indicator_thresholds\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Evaluator] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:1100229,xor_checksum:1683653538,sum_checksum:1683653538\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733735157487\n",
            "last_update_time_since_epoch: 1733735157487\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'model': [Artifact(artifact: id: 48\n",
            "type_id: 27\n",
            "uri: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733738965929\n",
            "last_update_time_since_epoch: 1733738965929\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")], 'baseline_model': []},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 42\n",
            "I0000 00:00:1733739143.299886   17988 chttp2_server.cc:1023] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {created_time:\"2024-12-09T10:12:23.299876228+00:00\", children:[UNKNOWN:socket: Address family not supported by protocol (97) {created_time:\"2024-12-09T10:12:23.299863866+00:00\"}]}\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=42, input_dict={'examples': [Artifact(artifact: id: 1\n",
            "type_id: 16\n",
            "uri: \"output/sentiment-pipeline/CsvExampleGen/examples/2\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"file_format\"\n",
            "  value {\n",
            "    string_value: \"tfrecords_gzip\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:1100229,xor_checksum:1683653538,sum_checksum:1683653538\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Examples\"\n",
            "create_time_since_epoch: 1733735157487\n",
            "last_update_time_since_epoch: 1733735157487\n",
            ", artifact_type: id: 16\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            "base_type: DATASET\n",
            ")], 'model': [Artifact(artifact: id: 48\n",
            "type_id: 27\n",
            "uri: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733738965929\n",
            "last_update_time_since_epoch: 1733738965929\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")], 'baseline_model': []}, output_dict=defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"output/sentiment-pipeline/Evaluator/evaluation/42\"\n",
            ", artifact_type: name: \"ModelEvaluation\"\n",
            ")], 'blessing': [Artifact(artifact: uri: \"output/sentiment-pipeline/Evaluator/blessing/42\"\n",
            ", artifact_type: name: \"ModelBlessing\"\n",
            ")]}), exec_properties={'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"FalsePositives\"\\n        },\\n        {\\n          \"class_name\": \"TruePositives\"\\n        },\\n        {\\n          \"class_name\": \"FalseNegatives\"\\n        },\\n        {\\n          \"class_name\": \"TrueNegatives\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"label\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'fairness_indicator_thresholds': 'null', 'example_splits': 'null'}, execution_output_uri='output/sentiment-pipeline/Evaluator/.system/executor_execution/42/executor_output.pb', stateful_working_dir='output/sentiment-pipeline/Evaluator/.system/stateful_working_dir/8d2106ea-2f80-4adf-b461-9eda05e5330d', tmp_dir='output/sentiment-pipeline/Evaluator/.system/executor_execution/42/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
            "    base_type: EVALUATE\n",
            "  }\n",
            "  id: \"Evaluator\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Evaluator\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"baseline_model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Latest_blessed_model_resolver\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Latest_blessed_model_resolver\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "            base_type: DATASET\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "      min_count: 1\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"blessing\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelBlessing\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"evaluation\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelEvaluation\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"eval_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"AUC\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalsePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TruePositives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"FalseNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"TrueNegatives\\\"\\n        },\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.0001,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"label\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"example_splits\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"fairness_indicator_thresholds\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "upstream_nodes: \"Latest_blessed_model_resolver\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"sentiment-pipeline\"\n",
            ", pipeline_run_id='20241209-100825.750396', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:udf_utils.get_fn {'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"FalsePositives\"\\n        },\\n        {\\n          \"class_name\": \"TruePositives\"\\n        },\\n        {\\n          \"class_name\": \"FalseNegatives\"\\n        },\\n        {\\n          \"class_name\": \"TrueNegatives\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"label\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'fairness_indicator_thresholds': 'null', 'example_splits': 'null'} 'custom_eval_shared_model'\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using output/sentiment-pipeline/Trainer/model/40/Format-Serving as  model.\n",
            "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
            "INFO:absl:Evaluating model.\n",
            "INFO:absl:udf_utils.get_fn {'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\"\\n        },\\n        {\\n          \"class_name\": \"AUC\"\\n        },\\n        {\\n          \"class_name\": \"FalsePositives\"\\n        },\\n        {\\n          \"class_name\": \"TruePositives\"\\n        },\\n        {\\n          \"class_name\": \"FalseNegatives\"\\n        },\\n        {\\n          \"class_name\": \"TrueNegatives\"\\n        },\\n        {\\n          \"class_name\": \"BinaryAccuracy\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.0001,\\n              \"direction\": \"HIGHER_IS_BETTER\"\\n            },\\n            \"value_threshold\": {\\n              \"lower_bound\": 0.5\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"label\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}', 'fairness_indicator_thresholds': 'null', 'example_splits': 'null'} 'custom_extractors'\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  model_names: \"\"\n",
            "}\n",
            "\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  model_names: \"\"\n",
            "}\n",
            "\n",
            "INFO:absl:eval_shared_models have model_types: {'tf_keras'}\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"label\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"ExampleCount\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"AUC\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalsePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TruePositives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"FalseNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"TrueNegatives\"\n",
            "  }\n",
            "  metrics {\n",
            "    class_name: \"BinaryAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.5\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  model_names: \"\"\n",
            "}\n",
            "\n",
            "INFO:absl:Evaluation complete. Results written to output/sentiment-pipeline/Evaluator/evaluation/42.\n",
            "INFO:absl:Checking validation results.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:112: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:112: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "INFO:absl:Blessing result True written to output/sentiment-pipeline/Evaluator/blessing/42.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 42 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir output/sentiment-pipeline/Evaluator/.system/stateful_working_dir/8d2106ea-2f80-4adf-b461-9eda05e5330d\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"output/sentiment-pipeline/Evaluator/evaluation/42\"\n",
            ", artifact_type: name: \"ModelEvaluation\"\n",
            ")], 'blessing': [Artifact(artifact: uri: \"output/sentiment-pipeline/Evaluator/blessing/42\"\n",
            ", artifact_type: name: \"ModelBlessing\"\n",
            ")]}) for execution 42\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Evaluator is finished.\n",
            "INFO:absl:node Pusher is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.pusher.component.Pusher\"\n",
            "    base_type: DEPLOY\n",
            "  }\n",
            "  id: \"Pusher\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Pusher\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model_blessing\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Evaluator\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Evaluator\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ModelBlessing\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"blessing\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"pushed_model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"PushedModel\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"push_destination\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"output/serving_model\\\"\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"Evaluator\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "INFO:absl:[Pusher] Resolved inputs: ({'model_blessing': [Artifact(artifact: id: 52\n",
            "type_id: 34\n",
            "uri: \"output/sentiment-pipeline/Evaluator/blessing/42\"\n",
            "custom_properties {\n",
            "  key: \"blessed\"\n",
            "  value {\n",
            "    int_value: 1\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model\"\n",
            "  value {\n",
            "    string_value: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model_id\"\n",
            "  value {\n",
            "    int_value: 48\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ModelBlessing\"\n",
            "create_time_since_epoch: 1733739155548\n",
            "last_update_time_since_epoch: 1733739155548\n",
            ", artifact_type: id: 34\n",
            "name: \"ModelBlessing\"\n",
            ")], 'model': [Artifact(artifact: id: 48\n",
            "type_id: 27\n",
            "uri: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733738965929\n",
            "last_update_time_since_epoch: 1733738965929\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")]},)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 43\n",
            "I0000 00:00:1733739155.675810   17988 chttp2_server.cc:1023] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {created_time:\"2024-12-09T10:12:35.675793305+00:00\", children:[UNKNOWN:socket: Address family not supported by protocol (97) {created_time:\"2024-12-09T10:12:35.675781281+00:00\"}]}\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=43, input_dict={'model_blessing': [Artifact(artifact: id: 52\n",
            "type_id: 34\n",
            "uri: \"output/sentiment-pipeline/Evaluator/blessing/42\"\n",
            "custom_properties {\n",
            "  key: \"blessed\"\n",
            "  value {\n",
            "    int_value: 1\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model\"\n",
            "  value {\n",
            "    string_value: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"current_model_id\"\n",
            "  value {\n",
            "    int_value: 48\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"ModelBlessing\"\n",
            "create_time_since_epoch: 1733739155548\n",
            "last_update_time_since_epoch: 1733739155548\n",
            ", artifact_type: id: 34\n",
            "name: \"ModelBlessing\"\n",
            ")], 'model': [Artifact(artifact: id: 48\n",
            "type_id: 27\n",
            "uri: \"output/sentiment-pipeline/Trainer/model/40\"\n",
            "custom_properties {\n",
            "  key: \"is_external\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"1.15.1\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "type: \"Model\"\n",
            "create_time_since_epoch: 1733738965929\n",
            "last_update_time_since_epoch: 1733738965929\n",
            ", artifact_type: id: 27\n",
            "name: \"Model\"\n",
            "base_type: MODEL\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"output/sentiment-pipeline/Pusher/pushed_model/43\"\n",
            ", artifact_type: name: \"PushedModel\"\n",
            "base_type: MODEL\n",
            ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"output/serving_model\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='output/sentiment-pipeline/Pusher/.system/executor_execution/43/executor_output.pb', stateful_working_dir='output/sentiment-pipeline/Pusher/.system/stateful_working_dir/5f2929ae-4c57-4fb4-a598-ce66c167e5d5', tmp_dir='output/sentiment-pipeline/Pusher/.system/executor_execution/43/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.pusher.component.Pusher\"\n",
            "    base_type: DEPLOY\n",
            "  }\n",
            "  id: \"Pusher\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"20241209-100825.750396\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"sentiment-pipeline.Pusher\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "            base_type: MODEL\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  inputs {\n",
            "    key: \"model_blessing\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Evaluator\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"20241209-100825.750396\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"sentiment-pipeline.Evaluator\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"ModelBlessing\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"blessing\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"pushed_model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"PushedModel\"\n",
            "          base_type: MODEL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"push_destination\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"output/serving_model\\\"\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"Evaluator\"\n",
            "upstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "    enable_cache: true\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"sentiment-pipeline\"\n",
            ", pipeline_run_id='20241209-100825.750396', top_level_pipeline_run_id=None, frontend_url=None)\n",
            "INFO:absl:Model version: 1733739155\n",
            "INFO:absl:Model written to serving path output/serving_model/1733739155.\n",
            "INFO:absl:Model pushed to output/sentiment-pipeline/Pusher/pushed_model/43.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 43 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Deleted stateful_working_dir output/sentiment-pipeline/Pusher/.system/stateful_working_dir/5f2929ae-4c57-4fb4-a598-ce66c167e5d5\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"output/sentiment-pipeline/Pusher/pushed_model/43\"\n",
            ", artifact_type: name: \"PushedModel\"\n",
            "base_type: MODEL\n",
            ")]}) for execution 43\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:node Pusher is finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/output.zip /content/output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zhEmtfNO4qq",
        "outputId": "3a30d788-fef9-4515-d88f-9f19bfe43a33"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/output/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/_wheels/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+092716595856e59e782dfe9aeb3d7c2f8db435eaef91601292765b5acf88867f-py3-none-any.whl (deflated 14%)\n",
            "updating: content/output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+092716595856e59e782dfe9aeb3d7c2f8db435eaef91601292765b5acf88867f-py3-none-any.whl (deflated 14%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/schema/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/schema/4/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/schema/4/schema.pbtxt (deflated 68%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/.system/executor_execution/4/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/SchemaGen/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/examples/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/examples/2/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/examples/2/Split-train/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/examples/2/Split-train/data_tfrecord-00000-of-00001.gz (deflated 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/examples/2/Split-eval/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/examples/2/Split-eval/data_tfrecord-00000-of-00001.gz (deflated 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/.system/driver_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/.system/driver_execution/1733735153629782/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/.system/executor_execution/2/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/CsvExampleGen/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/statistics/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/statistics/3/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/statistics/3/Split-train/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/statistics/3/Split-train/FeatureStats.pb (deflated 58%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/statistics/3/Split-eval/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/statistics/3/Split-eval/FeatureStats.pb (deflated 57%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/.system/executor_execution/3/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/StatisticsGen/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/metadata.sqlite (deflated 87%)\n",
            "updating: content/output/sentiment-pipeline/Transform/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/assets/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/fingerprint.pb (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/variables/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/variables/variables.index (deflated 33%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/variables/variables.data-00000-of-00001 (deflated 22%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transform_fn/saved_model.pb (deflated 74%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transformed_metadata/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/transformed_metadata/schema.pbtxt (deflated 54%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/metadata/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transform_graph/6/metadata/schema.pbtxt (deflated 68%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_schema/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_schema/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_schema/6/schema.pbtxt (deflated 54%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_stats/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_stats/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_stats/6/FeatureStats.pb (deflated 58%)\n",
            "updating: content/output/sentiment-pipeline/Transform/updated_analyzer_cache/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/updated_analyzer_cache/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_anomalies/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_anomalies/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/post_transform_anomalies/6/SchemaDiff.pb (deflated 32%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transformed_examples/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transformed_examples/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transformed_examples/6/Split-train/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transformed_examples/6/Split-train/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transformed_examples/6/Split-eval/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/transformed_examples/6/Split-eval/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/.system/executor_execution/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/pre_transform_stats/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/pre_transform_stats/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/pre_transform_stats/6/FeatureStats.pb (deflated 56%)\n",
            "updating: content/output/sentiment-pipeline/Transform/pre_transform_schema/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/pre_transform_schema/6/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Transform/pre_transform_schema/6/schema.pbtxt (deflated 68%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/anomalies/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/anomalies/5/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/anomalies/5/Split-train/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/anomalies/5/Split-train/SchemaDiff.pb (deflated 40%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/anomalies/5/Split-eval/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/anomalies/5/Split-eval/SchemaDiff.pb (deflated 40%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/.system/executor_execution/5/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/ExampleValidator/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model_run/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model_run/7/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/.system/executor_execution/7/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/assets/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/fingerprint.pb (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/variables/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/variables/variables.index (deflated 59%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/variables/variables.data-00000-of-00001 (deflated 40%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/saved_model.pb (deflated 79%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/Format-Serving/keras_metadata.pb (deflated 85%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/logs/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/logs/train/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/logs/train/events.out.tfevents.1733735193.d9a495f2e273.1766.0.v2 (deflated 81%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/logs/validation/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Trainer/model/7/logs/validation/events.out.tfevents.1733735207.d9a495f2e273.1766.1.v2 (deflated 36%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/evaluation/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/blessing/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/.system/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/.system/executor_execution/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/.system/executor_execution/8/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/.system/stateful_working_dir/ (stored 0%)\n",
            "updating: content/output/sentiment-pipeline/Evaluator/.system/stateful_working_dir/ec1428f5-c54d-4d33-a973-53769226c405/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+0b8077a61e2c0383073800a3664fff428135aea3c2be7fba77e3e885d8b65fea-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+75d7aa9d7528ef432ebbc8d1d3a51f7d500862fba6d46f55c5250c6a86b09c7f-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+0b8077a61e2c0383073800a3664fff428135aea3c2be7fba77e3e885d8b65fea-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+75d7aa9d7528ef432ebbc8d1d3a51f7d500862fba6d46f55c5250c6a86b09c7f-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Transform-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+8c9273b7aff1431617ea2018a7732867b6881586473fb26de5bb77d7fd18e99b-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Tuner-0.0+0b8077a61e2c0383073800a3664fff428135aea3c2be7fba77e3e885d8b65fea-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/_wheels/tfx_user_code_Trainer-0.0+75d7aa9d7528ef432ebbc8d1d3a51f7d500862fba6d46f55c5250c6a86b09c7f-py3-none-any.whl (deflated 14%)\n",
            "  adding: content/output/sentiment-pipeline/CsvExampleGen/.system/driver_execution/1733737826977641/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/CsvExampleGen/.system/driver_execution/1733737585999434/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/CsvExampleGen/.system/driver_execution/1733738906193336/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/CsvExampleGen/.system/driver_execution/1733738733463235/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/best_hyperparameters/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/best_hyperparameters/16/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/best_hyperparameters/41/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/best_hyperparameters/41/best_hyperparameters.txt (deflated 75%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/best_hyperparameters/23/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/best_hyperparameters/23/best_hyperparameters.txt (deflated 75%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/executor_execution/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/executor_execution/16/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/executor_execution/33/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/executor_execution/41/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/executor_execution/23/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/stateful_working_dir/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/stateful_working_dir/91c9ccd6-78c3-4fa9-a289-13842b19759b/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/.system/stateful_working_dir/b96d8bd6-d755-40e2-9605-e630a85671d7/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/tuner_results/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/tuner_results/16/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/tuner_results/41/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/tuner_results/41/tuner_results.json (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/tuner_results/23/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Tuner/tuner_results/23/tuner_results.json (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/.system/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/.system/executor_execution/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/.system/executor_execution/43/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/.system/stateful_working_dir/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/variables/variables.index (deflated 59%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/variables/variables.data-00000-of-00001 (deflated 40%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/saved_model.pb (deflated 79%)\n",
            "  adding: content/output/sentiment-pipeline/Pusher/pushed_model/43/keras_metadata.pb (deflated 85%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/variables/variables.index (deflated 33%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/variables/variables.data-00000-of-00001 (deflated 22%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transform_fn/saved_model.pb (deflated 74%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transformed_metadata/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/transformed_metadata/schema.pbtxt (deflated 54%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/metadata/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/31/metadata/schema.pbtxt (deflated 68%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/variables/variables.index (deflated 33%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/variables/variables.data-00000-of-00001 (deflated 22%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transform_fn/saved_model.pb (deflated 74%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transformed_metadata/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/transformed_metadata/schema.pbtxt (deflated 54%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/metadata/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/39/metadata/schema.pbtxt (deflated 68%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/variables/variables.index (deflated 33%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/variables/variables.data-00000-of-00001 (deflated 22%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transform_fn/saved_model.pb (deflated 74%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transformed_metadata/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/transformed_metadata/schema.pbtxt (deflated 54%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/metadata/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transform_graph/14/metadata/schema.pbtxt (deflated 68%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_schema/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_schema/31/schema.pbtxt (deflated 54%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_schema/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_schema/39/schema.pbtxt (deflated 54%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_schema/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_schema/14/schema.pbtxt (deflated 54%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_stats/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_stats/31/FeatureStats.pb (deflated 58%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_stats/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_stats/39/FeatureStats.pb (deflated 58%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_stats/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_stats/14/FeatureStats.pb (deflated 58%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/updated_analyzer_cache/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/updated_analyzer_cache/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/updated_analyzer_cache/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_anomalies/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_anomalies/31/SchemaDiff.pb (deflated 32%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_anomalies/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_anomalies/39/SchemaDiff.pb (deflated 32%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_anomalies/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/post_transform_anomalies/14/SchemaDiff.pb (deflated 32%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/31/Split-train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/31/Split-train/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/31/Split-eval/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/31/Split-eval/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/39/Split-train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/39/Split-train/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/39/Split-eval/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/39/Split-eval/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/14/Split-train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/14/Split-train/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/14/Split-eval/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/transformed_examples/14/Split-eval/transformed_examples-00000-of-00001.gz (deflated 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/.system/executor_execution/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/.system/executor_execution/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/.system/executor_execution/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_stats/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_stats/31/FeatureStats.pb (deflated 56%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_stats/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_stats/39/FeatureStats.pb (deflated 56%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_stats/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_stats/14/FeatureStats.pb (deflated 56%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_schema/31/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_schema/31/schema.pbtxt (deflated 68%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_schema/39/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_schema/39/schema.pbtxt (deflated 68%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_schema/14/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Transform/pre_transform_schema/14/schema.pbtxt (deflated 68%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model_run/32/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model_run/15/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model_run/40/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model_run/24/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/.system/executor_execution/32/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/.system/executor_execution/15/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/.system/executor_execution/40/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/.system/executor_execution/24/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/variables/variables.index (deflated 59%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/saved_model.pb (deflated 79%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/Format-Serving/keras_metadata.pb (deflated 85%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/logs/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/logs/train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/logs/train/events.out.tfevents.1733738761.d9a495f2e273.17028.0.v2 (deflated 81%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/logs/validation/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/32/logs/validation/events.out.tfevents.1733738775.d9a495f2e273.17028.1.v2 (deflated 36%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/variables/variables.index (deflated 59%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/variables/variables.data-00000-of-00001 (deflated 40%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/saved_model.pb (deflated 79%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/Format-Serving/keras_metadata.pb (deflated 85%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/logs/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/logs/train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/logs/train/events.out.tfevents.1733737614.d9a495f2e273.11941.0.v2 (deflated 81%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/logs/validation/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/15/logs/validation/events.out.tfevents.1733737628.d9a495f2e273.11941.1.v2 (deflated 37%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/variables/variables.index (deflated 59%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/variables/variables.data-00000-of-00001 (deflated 40%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/saved_model.pb (deflated 79%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/Format-Serving/keras_metadata.pb (deflated 85%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/logs/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/logs/train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/logs/train/events.out.tfevents.1733738937.d9a495f2e273.17988.0.v2 (deflated 81%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/logs/validation/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/40/logs/validation/events.out.tfevents.1733738952.d9a495f2e273.17988.1.v2 (deflated 37%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/assets/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/variables/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/variables/variables.index (deflated 59%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/saved_model.pb (deflated 79%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/Format-Serving/keras_metadata.pb (deflated 85%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/logs/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/logs/train/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/logs/train/events.out.tfevents.1733738391.d9a495f2e273.13091.0.v2 (deflated 81%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/logs/validation/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Trainer/model/24/logs/validation/events.out.tfevents.1733738412.d9a495f2e273.13091.1.v2 (deflated 37%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/evaluation/42/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/evaluation/42/eval_config.json (deflated 66%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/evaluation/42/attributions-00000-of-00001.tfrecord (deflated 17%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/evaluation/42/plots-00000-of-00001.tfrecord (deflated 17%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/evaluation/42/metrics-00000-of-00001.tfrecord (deflated 43%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/evaluation/42/validations.tfrecord (deflated 8%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/blessing/42/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/blessing/42/BLESSED (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/.system/executor_execution/42/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/.system/executor_execution/25/ (stored 0%)\n",
            "  adding: content/output/sentiment-pipeline/Evaluator/.system/stateful_working_dir/0d6d9137-6080-40fb-9b13-e45848e92c80/ (stored 0%)\n",
            "  adding: content/output/serving_model/ (stored 0%)\n",
            "  adding: content/output/serving_model/1733739155/ (stored 0%)\n",
            "  adding: content/output/serving_model/1733739155/assets/ (stored 0%)\n",
            "  adding: content/output/serving_model/1733739155/fingerprint.pb (stored 0%)\n",
            "  adding: content/output/serving_model/1733739155/variables/ (stored 0%)\n",
            "  adding: content/output/serving_model/1733739155/variables/variables.index (deflated 59%)\n",
            "  adding: content/output/serving_model/1733739155/variables/variables.data-00000-of-00001 (deflated 40%)\n",
            "  adding: content/output/serving_model/1733739155/saved_model.pb (deflated 79%)\n",
            "  adding: content/output/serving_model/1733739155/keras_metadata.pb (deflated 85%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autopep8 --in-place --aggressive --aggressive modules/components.py ./local_pipeline.py modules/transform.py modules/trainer.py modules/tuner.py\n"
      ],
      "metadata": {
        "id": "qJBbM7i5QXxZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pylint modules/components.py ./local_pipeline.py modules/transform.py modules/trainer.py modules/tuner.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mANMm563QYMT",
        "outputId": "b620ce2b-ea1c-466a-fdb3-0af44690d025"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************* Module components\n",
            "modules/components.py:42:0: C0301: Line too long (111/100) (line-too-long)\n",
            "modules/components.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
            "modules/components.py:24:0: R0913: Too many arguments (6/5) (too-many-arguments)\n",
            "modules/components.py:24:0: R0917: Too many positional arguments (6/5) (too-many-positional-arguments)\n",
            "modules/components.py:24:0: R0914: Too many local variables (19/15) (too-many-locals)\n",
            "modules/components.py:45:13: E1101: Module 'tfx.proto.example_gen_pb2' has no 'Output' member (no-member)\n",
            "modules/components.py:46:21: E1101: Module 'tfx.proto.example_gen_pb2' has no 'SplitConfig' member (no-member)\n",
            "modules/components.py:47:12: E1101: Module 'tfx.proto.example_gen_pb2' has no 'SplitConfig' member (no-member)\n",
            "modules/components.py:48:12: E1101: Module 'tfx.proto.example_gen_pb2' has no 'SplitConfig' member (no-member)\n",
            "modules/components.py:81:19: E1101: Module 'tfx.proto.trainer_pb2' has no 'TrainArgs' member (no-member)\n",
            "modules/components.py:85:18: E1101: Module 'tfx.proto.trainer_pb2' has no 'EvalArgs' member (no-member)\n",
            "modules/components.py:133:25: E1101: Module 'tfx.proto.pusher_pb2' has no 'PushDestination' member (no-member)\n",
            "modules/components.py:134:23: E1101: Module 'tfx.proto.pusher_pb2' has no 'PushDestination' member (no-member)\n",
            "modules/components.py:144:19: E1101: Module 'tfx.proto.trainer_pb2' has no 'TrainArgs' member (no-member)\n",
            "modules/components.py:147:18: E1101: Module 'tfx.proto.trainer_pb2' has no 'EvalArgs' member (no-member)\n",
            "************* Module local_pipeline\n",
            "local_pipeline.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
            "local_pipeline.py:22:4: W0621: Redefining name 'components' from outer scope (line 51) (redefined-outer-name)\n",
            "local_pipeline.py:22:16: W0621: Redefining name 'pipeline_root' from outer scope (line 17) (redefined-outer-name)\n",
            "************* Module trainer\n",
            "modules/trainer.py:3:0: C0301: Line too long (113/100) (line-too-long)\n",
            "modules/trainer.py:9:0: E0401: Unable to import 'tensorflow.keras' (import-error)\n",
            "modules/trainer.py:9:0: E0611: No name 'keras' in module 'tensorflow' (no-name-in-module)\n",
            "modules/trainer.py:35:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "modules/trainer.py:84:13: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/trainer.py:98:12: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/trainer.py:102:18: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/trainer.py:103:17: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/trainer.py:148:27: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/trainer.py:152:9: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/trainer.py:155:9: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "************* Module tuner\n",
            "modules/tuner.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
            "modules/tuner.py:6:0: E0401: Unable to import 'tensorflow.keras' (import-error)\n",
            "modules/tuner.py:6:0: E0611: No name 'keras' in module 'tensorflow' (no-name-in-module)\n",
            "modules/tuner.py:8:0: E0401: Unable to import 'tensorflow.keras.callbacks' (import-error)\n",
            "modules/tuner.py:8:0: E0611: No name 'keras' in module 'tensorflow' (no-name-in-module)\n",
            "modules/tuner.py:28:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "modules/tuner.py:32:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "modules/tuner.py:36:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "modules/tuner.py:53:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "modules/tuner.py:73:13: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/tuner.py:87:12: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/tuner.py:90:18: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/tuner.py:91:13: E1101: Module 'tensorflow' has no 'keras' member (no-member)\n",
            "modules/tuner.py:98:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
            "modules/tuner.py:4:0: C0411: standard import \"typing.NamedTuple\" should be placed before third party imports \"keras_tuner\", \"tensorflow\", \"tensorflow_transform\" (wrong-import-order)\n",
            "modules/tuner.py:8:0: C0412: Imports from package tensorflow are not grouped (ungrouped-imports)\n",
            "modules/tuner.py:1:0: R0801: Similar lines in 2 files\n",
            "==trainer:[54:60]\n",
            "==tuner:[40:46]\n",
            "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
            "        file_pattern=file_pattern,\n",
            "        batch_size=batch_size,\n",
            "        features=transform_feature_spec,\n",
            "        reader=gzip_reader_fn,\n",
            "        num_epochs=num_epochs, (duplicate-code)\n",
            "\n",
            "------------------------------------------------------------------\n",
            "Your code has been rated at 0.49/10 (previous run: 0.63/10, -0.14)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_M-5YuISEIw"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}